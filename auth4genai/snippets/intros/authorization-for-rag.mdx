## Why using this feature

- **Secure**: Prevents unauthorized data access.
- **Compliant**: Protects sensitive information.
- **Efficient**: Adds fine-grained access control to RAG.

<CodeGroup>

```javascript src/lib/auth0-ai.ts
import { FGARetriever } from "@auth0/ai-langchain/RAG";
import { MemoryStore, RetrievalChain } from "./helpers/memory-store";
import { readDocuments } from "./helpers/read-documents";

async function main() {
  // UserID
  const user = "user1";
  const documents = await readDocuments();
  // 1. Call helper function to load LangChain MemoryStore
  const vectorStore = await MemoryStore.fromDocuments(documents);
  // 2. Call helper function to create a LangChain retrieval chain.
  const retrievalChain = await RetrievalChain.create({
    // 3. Decorate the retriever with the FGARetriever to check permissions.
    retriever: FGARetriever.create({
      retriever: vectorStore.asRetriever(),
      buildQuery: (doc) => ({
        user: `user:${user}`,
        object: `doc:${doc.metadata.id}`,
        relation: "viewer",
      }),
    }),
  });

  // 4. Execute the query
  const { answer } = await retrievalChain.query({
    query: "Show me forecast for ZEKO?",
  });

  console.log(answer);
}

main().catch(console.error);
```

</CodeGroup>

## How it works

Generative AI apps and agents often need to ground responses in retrieved documents—for example:

- A user asks for a forecast based on sales data.
- Summarize internal reports or policies.
- Pull insights from product or customer docs.

Auth0 AI – Authorization for RAG ensures that only the documents a user is allowed to see are used, so responses are both relevant and compliant.

<Frame>
<img
  className="block dark:hidden"
  src="https://cdn.auth0.com/website/auth0-ai/assets/diagrams/rag-light.png"
  alt="Calling APIs"
/>

<img
  className="hidden dark:block"
  src="https://cdn.auth0.com/website/auth0-ai/assets/diagrams/rag-dark.png"
  alt="Calling APIs"
/>
</Frame>

<Steps>
  <Step title="Request Setup">
    In this first step, the user initiates the flow by making a natural language request to the AI agent. The request is a plain-text instruction like: “Show me ACME forecast.”
    - Intent Expression: The user communicates their intent — retrieving forecast data — without referencing technical tools or document sources.
    - Input Capture: The AI agent receives the query and parses the key instruction (ACME forecast).
    - Purpose: This step sets the stage for the AI agent to determine which tool should be used to satisfy the request.
  </Step>
  <Step title="Tool Invocation">
    The AI agent invokes the Forecast tool to fulfill the request. This tool relies on external data retrieval capabilities.
    - Tool Invocation: The AI agent routes the user’s query to the Forecast tool.
    - Action: The tool initiates a semantic search process to locate relevant documents in the vector database.
    - Purpose: This step bridges the user request with the backend knowledge base.
  </Step>
  <Step title="Semantic Search">
    The system performs a semantic search against the vector database to retrieve candidate documents related to the query.
    - Information Retrieval: The semantic search locates documents that match the meaning of the request (“ACME forecast”).
    - Output: A set of relevant documents is returned.
    - Purpose: This ensures the AI agent has content to ground its response in contextually accurate data.
  </Step>
  <Step title="Access Filtering">
    Auth0 AI applies Fine-Grained Authorization (FGA) to filter documents based on user permissions.
    - Access Control Enforcement: Documents are evaluated against the requesting user’s access rights.
    - Filtering: Only the subset of documents the user is authorized to view is passed forward.
    - Purpose: This ensures that the AI’s answer is both relevant and compliant with security constraints.
  </Step>
  <Step title="Response Generation">
    The AI agent generates a final response using the filtered documents.
    - Answer Generation: The relevant and permitted documents are used to compose a grounded forecast response.
    - Output Delivery: The AI agent provides the user with the requested forecast in natural language.
    - Purpose: This completes the flow, delivering an accurate, permission-compliant answer to the user.
  </Step>
</Steps>


## The challenge: Securing data in RAG pipelines

Retrieval-Augmented Generation (RAG) is a powerful technique that enhances Large Language Models (LLMs) by providing them with relevant, up-to-date information from external data sources, such as a company's internal knowledge base or document repository.

However, without proper access controls, a RAG pipeline could retrieve documents containing sensitive information (e.g., financial reports, HR documents, strategic plans) and use them to generate a response for a user who should not have access to that data. This could lead to serious data breaches and compliance violations. Simply filtering based on user roles is often insufficient for managing the complex, relationship-based permissions found in real-world applications.

## The solution: Auth0 Fine-Grained Authorization (FGA)

To solve this challenge, Auth0 for AI Agents uses [**Auth0 Fine-Grained Authorization (FGA)**](https://auth0.com/fine-grained-authorization). Auth0 FGA is a flexible, high-performance authorization service for applications that require a sophisticated permissions system. It implements Relationship-Based Access Control (ReBAC) to manage permissions at large-scale. Auth0 FGA is built on top of [OpenFGA](https://openfga.dev/), created by Auth0, which is a [CNCF](https://cncf.io/) sandbox project.

Auth0 FGA allows you to decouple your authorization logic from your application code. Instead of embedding complex permission rules directly into your application, you define an authorization model and store relationship data in Auth0 FGA. Your application can then query Auth0 FGA at runtime to make real-time access decisions.

### Fine-Grained Access in RAG

Integrating Auth0 FGA into your RAG pipeline ensures that every document is checked against the user's permissions before it's passed to the LLM.

<Frame>
  <img
    className="hidden dark:block"
    src="/img/intro/how_it_works_with_rag_diagram_dark.png"
    alt="Authorization for RAG"
  />
  <img
    className="block dark:hidden"
    src="/img/intro/how_it_works_with_rag_diagram_light.png"
    alt="Authorization for RAG"
  />
</Frame>

The process works as follows:

<Steps>
  <Step title="Authorization model">
    First, you define your authorization model in Auth0 FGA. This model
    specifies the types of objects (e.g., `document`), the possible
    relationships between users and objects (e.g., `owner`, `editor`, `viewer`),
    and the rules that govern access.
  </Step>
  <Step title="Store relationships">
    You store permissions as 'tuples' in Auth0 FGA. A tuple is the core data
    element, representing a specific relationship in the format of `(user,
    relation, object)`. For example, `user:anne` is a `viewer` of
    `document:2024-financials`.
  </Step>
  <Step title="Fetch and filter">
    When a user submits a query to your AI agent, your backend first
    fetches relevant documents from a vector database and then makes a
    permission check call to Auth0 FGA. This call asks, "Is this user allowed to
    view these documents?". Our AI framework SDKs abstract this and make it as
    easy as plugging in a filter in your retriever tool.
  </Step>
  <Step title="Secure retrieval">
    Auth0 FGA determines if the user is authorized to access the documents. Your
    application backend uses this data to filter the results from the vector
    database and only sends the authorized documents to the LLM.
  </Step>
</Steps>
