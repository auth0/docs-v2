---
title: LlamaIndex SDK
description: Auth0 for AI Agents LlamaIndex SDKs make it easy for developers to integrate with and secure AI agent workflows using LlamaIndex.
sidebarTitle: LlamaIndex SDKs
---

## JavaScript & TypeScript

### [Auth0 AI for LlamaIndex](https://github.com/auth0/auth0-ai-js/tree/main/packages/ai-llamaindex)

This SDK provides building blocks for using Auth0 for AI Agents with [LlamaIndex](https://www.llamaindex.ai/). Includes a RAG Retriever for using OpenFGA, tools for implementing asynchronous user authentication, tools for getting access tokens for third-party connections, and [OpenFGA-based](https://openfga.dev/) tool authorizers. It supports:

- A RAG Retriever for using OpenFGA
- Tools for implementing asynchronous user authentication
- Tools for getting access tokens for third-party connections
- OpenFGA-based tool authorizers

```bash wrap lines
npm install @auth0/ai-llamaindex
```

Below are examples that demonstrate how to integrate Okta FGA with RAG scenarios. For more examples, click [here](https://github.com/auth0/auth0-ai-js/tree/main/examples/authorization-for-rag/llamaindex).

<AccordionGroup>
<Accordion title="Using Authorization for RAG">
Auth0AI can leverage OpenFGA to authorize RAG applications. The FGARetriever can be used to filter documents based on access control checks defined in Okta FGA. This retriever performs batch checks on retrieved documents, returning only the ones that pass the specified access criteria.

Create a Retriever instance using the `FGARetriever.create` method.

```javascript lines focus={3, 24-30, 34-36} expandable
import { Settings, VectorStoreIndex } from "llamaindex";
import { OpenAIEmbedding, openai } from "@llamaindex/openai";
import { FGARetriever } from "@auth0/ai-llamaindex";
import { readDocuments } from "./helpers/read-documents";

Settings.llm = openai({
  model: "gpt-4o-mini",
});

Settings.embedModel = new OpenAIEmbedding({ model: "text-embedding-3-small" });

async function main() {
  console.log(
    "\n..:: LlamaIndex Example: Retrievers with Okta FGA (Fine-Grained Authorization)\n\n"
  );

  // UserID
  const user = "user1";
  const documents = await readDocuments();
  const vectorStoreIndex = await VectorStoreIndex.fromDocuments(documents);

  const queryEngine = vectorStoreIndex.asQueryEngine({
    // Decorate the retriever with the FGARetriever to check the permissions.
    retriever: FGARetriever.create({
      retriever: vectorStoreIndex.asRetriever(),
      buildQuery: (document) => ({
        user: `user:${user}`,
        object: `doc:${document.node.metadata.id}`,
        relation: "viewer",
      }),
    }),
  });

  const vsiResponse = await queryEngine.query({
    query: "Show me forecast for ZEKO?",
  });

  console.log(vsiResponse.toString());
}

main().catch(console.error);
```
</Accordion>
</AccordionGroup>

## Python

### [Auth0 AI for LlamaIndex](https://github.com/auth0/auth0-ai-python/tree/main/packages/auth0-ai-llamaindex)

This SDK provides building blocks for using Auth0 for AI Agents with LlamaIndex. Includes a RAG Retriever for using OpenFGA, tools for implementing asynchronous user authentication, tools for getting access tokens for third-party connections, and OpenFGA-based tool authorizers. It supports:

- A RAG Retriever for using OpenFGA,
- Tools for getting access tokens for third-party connections,
- OpenFGA-based tool authorizers.

```bash wrap lines
pip install auth0-ai-llamaindex
```

Below is a code sample for using Okta FGA authorization in a RAG workflow with LlamaIndex for Python. It shows how to filter retrieved documents based on user permissions before passing them to your model. For more examples, click [here](https://github.com/auth0-lab/auth0-ai-python/tree/main/packages/auth0-ai-llamaindex).

<AccordionGroup>
<Accordion title="Using Authorization for RAG">
The `FGARetriever` can be used to filter documents based on access control checks defined in Okta FGA. This retriever performs batch checks on retrieved documents, returning only the ones that pass the specified access criteria.

```python lines focus={2,21-28,31-34} expandable
from llama_index.core import VectorStoreIndex, Document
from auth0_ai_llamaindex import FGARetriever
from openfga_sdk.client.models import ClientCheckRequest
from openfga_sdk import ClientConfiguration
from openfga_sdk.credentials import CredentialConfiguration, Credentials

# Define some docs:
documents = [
    Document(text="This is a public doc", doc_id="public-doc"),
    Document(text="This is a private doc", doc_id="private-doc"),
]

# Create a vector store:
vector_store = VectorStoreIndex.from_documents(documents)

# Create a retriever:
base_retriever = vector_store.as_retriever()

# Create the FGA retriever wrapper.
# If not provided, FGA settings will be read from env variables: `FGA_STORE_ID`, `FGA_CLIENT_ID`, `FGA_CLIENT_SECRET`, etc.
retriever = FGARetriever(
    base_retriever,
    build_query=lambda node: ClientCheckRequest(
        user=f'user:{user}',
        object=f'doc:{node.ref_doc_id}',
        relation="viewer",
    )
)

# Create a query engine:
query_engine = RetrieverQueryEngine.from_args(
    retriever=retriever,
    llm=OpenAI()
)

# Query:
response = query_engine.query("What is the forecast for ZEKO?")

print(response)
```
</Accordion>
</AccordionGroup>
